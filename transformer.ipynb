{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a772bac-efdb-4e7b-b189-8699ae8a4dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb5927-0849-41cb-b148-43137b884af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df4bd1-364a-4c5a-9791-57e704010b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'L1_Train.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16608dab-feb7-4b4a-a944-bd49e21e8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fd804-238b-4610-87e1-3caacf54cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ace34-547e-4433-8404-1094b9171a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testTime = df['DateTime'][0]\n",
    "print(testTime.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed95a9-0109-4728-b2e0-483bcdf6d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = datetime.strptime('09:00:00', '%H:%M:%S').time()\n",
    "endTime = datetime.strptime('17:00:00', '%H:%M:%S').time()\n",
    "df_filt_9_to_17 = df[(df['DateTime'].dt.time >= startTime) & (df['DateTime'].dt.time <= endTime)]\n",
    "# [element for element in df if  startTime < element[1].time() < endTime]\n",
    "print(df_filt_9_to_17.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04211611-44c4-4918-b310-9c292575facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filt_9_to_17.to_csv('Checking_File.csv',index=False, header = True)  no problem in df_filt_9_to_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9ee85-2794-4d53-9691-1b2ddc77eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = pd.Timedelta(minutes=10)\n",
    "def generate_expected_times(start_time, end_time, interval):\n",
    "    times = []\n",
    "    current_time = pd.Timestamp.combine(pd.Timestamp.today(), start_time)\n",
    "    end_timestamp = pd.Timestamp.combine(pd.Timestamp.today(), end_time)\n",
    "    while current_time <= end_timestamp:\n",
    "        times.append(current_time.time())\n",
    "        # print(current_time.time(), interval)\n",
    "        current_time += interval\n",
    "    return times\n",
    "\n",
    "expected_times = generate_expected_times(startTime, endTime, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145c4b7-0635-422e-9176-b6dc774aad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expected_times[1]) #from 9 to 17 every 10\n",
    "check_list = np.zeros(49)\n",
    "print(check_list.shape, len(expected_times))\n",
    "# print(check_list, expected_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85393c2-bdbc-4a09-936f-1470c11cc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nowday = datetime.strptime('2024-01-01', '%Y-%M-%d').date()\n",
    "print(nowday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85b701-984b-4f18-9c34-4ca1a0d6aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "nowday = datetime.strptime('2024-08-01', '%Y-%M-%d').date()\n",
    "accepted_Days = []\n",
    "check_list = np.zeros(49)\n",
    "c = 0\n",
    "for idx, obj in enumerate(df['DateTime']):\n",
    "    if obj.date() != nowday or idx == len(df['DateTime'])-1:\n",
    "        v = sum(check_list)\n",
    "        # print(v)\n",
    "        if v == 47:\n",
    "            accepted_Days.append(nowday)    #date() for YMd, date for all\n",
    "        nowday = obj.date()\n",
    "        check_list = np.zeros(49)\n",
    "        c = 0\n",
    "    else:\n",
    "        if expected_times[c] < obj.time() < expected_times[c+1] and c < 47:\n",
    "            check_list[c] += 1\n",
    "            if c < 47:\n",
    "                c += 1\n",
    "print(len(accepted_Days))\n",
    "print(accepted_Days)  # Jan 1 2 3 4 5 7 8 9 10 12 13 16 18 20 21 22 23 24 25 27 28 29 30 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d354cce-106e-41c7-a703-8405b107a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'].dt.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c4aaa-f4fe-4277-a3a5-b3319304163b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for a, i in enumerate(accepted_Days):\n",
    "    print(i)\n",
    "    if a > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33f482-0cba-48b5-b3cf-ea617672a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.to_csv('Checking_File.csv',index=False, header = True)  #no problem in df_filt_9_to_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c69cdd0-27ba-49a2-b66a-e152df1d3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_days_set = set(accepted_Days)\n",
    "df_fill_10min = df_filt_9_to_17[df_filt_9_to_17['DateTime'].dt.date.isin(accepted_days_set)]\n",
    "\n",
    "# 查看篩選後的結果\n",
    "print(len(accepted_days_set))\n",
    "print(df_fill_10min.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3041b07-cf5c-41c3-839b-f54f74ea2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filt_9_to_17.info())\n",
    "print(df_fill_10min.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0e2ca-69ae-4bc9-9710-0db5a37f28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 DateTime 為索引\n",
    "df_new = df_fill_10min.copy()\n",
    "print(df_new.info())\n",
    "# df_new.to_csv('Checking_File.csv', index=False, header = True)\n",
    "df_new.set_index('DateTime', inplace=True)\n",
    "# df_new.to_csv('Checking_File2.csv', index=False, header = True)\n",
    "# 每 10 分鐘重採樣並計算平均\n",
    "df_resampled = df_new.resample('10min').mean().dropna()\n",
    "# df_new.to_csv('Checking_File3.csv', index=False, header = True)\n",
    "# df_resampled.to_csv('Checking_File4.csv', index=False, header = True)\n",
    "# 如果需要重設索引\n",
    "df_resampled.reset_index(inplace=True)\n",
    "# df_resampled.to_csv('Checking_File5.csv', index=False, header = True)\n",
    "print(df_resampled.info())\n",
    "#5136 / 48 = 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35d480-6e4b-4354-b79c-0d4272c05195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.loc[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d940a-fb48-4147-bb6b-2278f5bffcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed178f-2775-47dd-bc4d-81f437af69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled['timeSeries'] = df_resampled['DateTime'].dt.hour + df_resampled['DateTime'].dt.minute/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7a48b-4788-44de-98ed-466b6f4da4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79df7dff-98bb-4299-89da-774f8afd201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = df_resampled[['DateTime', 'timeSeries', 'LocationCode', 'WindSpeed(m/s)', 'Pressure(hpa)',\n",
    "       'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)', 'Power(mW)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f2564-f7cf-4e49-9b50-c6a0620fa7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7684aa2-9ae2-41c5-9896-9dcfe410afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = df_resampled.drop(columns='DateTime')\n",
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107e719-de7a-4d24-811f-91dc8716b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, out_size = 1, num_layers = 1, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.lstm_1_layer = nn.LSTM(input_size, hidden_size1, num_layers)\n",
    "        # self.connect1 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.lstm_2_layer = nn.LSTM(hidden_size1, hidden_size2, num_layers)\n",
    "        self.output_layer = nn.Linear(hidden_size2, out_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size1), torch.zeros(1,1,hidden_size1))\n",
    "    def forward(self, seq):\n",
    "        seq, (hidden_state1, cell_state1) = self.lstm_1_layer(seq)\n",
    "        seq = self.dropout(seq)\n",
    "        # seq = self.connect1(seq)\n",
    "        # seq = self.dropout(seq)\n",
    "        seq, (hidden_state2, cell_state2) = self.lstm_2_layer(seq)\n",
    "        seq = self.dropout(seq)\n",
    "        output = self.output_layer(seq)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592bccd-d3be-4bc2-bd99-60a300425976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data  # 假設是形狀為 (num_samples, n_steps, n_features) 的張量\n",
    "        self.targets = targets  # 假設是形狀為 (num_samples, target_size) 的張量\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx].unsqueeze(-1)\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee71c78-7285-4cca-b891-b619ce9a728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 檢查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # 如果有 GPU，則使用它\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # 否則使用 CPU\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f85177-3c66-4a3f-9929-a97fa0daaebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df_resampled.values\n",
    "##add normalization\n",
    "LSTM_MinMaxModel = MinMaxScaler().fit(df_values)\n",
    "data_tensor = LSTM_MinMaxModel.transform(df_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a1c19-3d9c-46ae-815d-7e23c0920b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = df_resampled.values\n",
    "X_data_tensor=data_tensor[:, :7]\n",
    "Y_data_tensor=data_tensor[:, 7]\n",
    "Y_data_tensor = Y_data_tensor.reshape(-1, 1)\n",
    "print(X_data_tensor.shape, Y_data_tensor.shape)\n",
    "\n",
    "NX = True\n",
    "NY = True\n",
    "##normalization\n",
    "if NX:\n",
    "    scaler_X = MinMaxScaler().fit(X_data_tensor)\n",
    "    train_data_n = scaler_X.transform(X_data_tensor)\n",
    "else:\n",
    "    train_data_n = X_data_tensor\n",
    "if NY:\n",
    "    scaler_Y = MinMaxScaler().fit(Y_data_tensor)\n",
    "    train_targets_n = scaler_Y.transform(Y_data_tensor)\n",
    "else:\n",
    "    train_targets_n = Y_data_tensor\n",
    "\n",
    "print(train_data_n.shape, train_targets_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e63cd-ea5a-46d0-8eb0-2f6e9d4753f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## expand numpy to sequence\n",
    "def to_sequence(data, stamp):\n",
    "    data_seq = []\n",
    "    for i in range(len(data) - stamp):\n",
    "        seq = data[i:i + stamp]\n",
    "        data_seq.append(seq)\n",
    "    return np.array(data_seq)\n",
    "    \n",
    "stamp = 48\n",
    "train_data = to_sequence(train_data_n, stamp)\n",
    "train_targets = to_sequence(train_targets_n, stamp).squeeze()\n",
    "print(train_data.shape, train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6249f97-2bb3-4604-9189-c938fe78f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data_n.reshape(107,48,7)  # 形狀應為 (num_samples, n_steps, n_features)\n",
    "# train_targets = train_targets_n.reshape(107,48)   # 形狀應為 (num_samples, target_size, 1)\n",
    "\n",
    "train_data_tensor = torch.tensor(train_data, dtype=torch.float32) #.to(device)\n",
    "train_targets_tensor = torch.tensor(train_targets, dtype=torch.float32) #.to(device)\n",
    "print(train_data_tensor.shape, train_targets_tensor.shape)\n",
    "\n",
    "# 創建數據集和數據加載器\n",
    "dataset = TimeSeriesDataset(train_data_tensor, train_targets_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)  # 設定 batch_size 和 shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f58370-29d8-4cb0-bf7a-e17311cbc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_input, train_target in train_loader:\n",
    "    print(train_input.shape, train_target.shape)\n",
    "    break\n",
    "print(train_input[0][0])\n",
    "print(train_target[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09687923-5cc3-446f-8b73-4c39625e0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 7  # 單變量的時間序列\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "out_size = 1\n",
    "num_layers = 1\n",
    "dropout = 0.2\n",
    "learning_rate = 0.001\n",
    "n_epochs = 100\n",
    "losses = []\n",
    "print(len(losses))\n",
    "output_list = []\n",
    "# 模型初始化\n",
    "model = LSTM(input_size, hidden_size1, hidden_size2, out_size, num_layers, dropout).to(device)\n",
    "for train_input, train_target in train_loader:\n",
    "    print(train_input.shape, train_target.shape)\n",
    "    break\n",
    "criterion = nn.MSELoss()  # 使用均方誤差作為損失函數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # 設定模型為訓練模式\n",
    "    for train_input, train_target in train_loader:  # 從 DataLoader 獲取每個批次\n",
    "        train_input, train_target = train_input.to(device), train_target.to(device)\n",
    "        optimizer.zero_grad()  # 清空之前的梯度\n",
    "\n",
    "        output = model(train_input)  # 將掩碼傳遞給模型的前向方法train_target,\n",
    "        loss = criterion(output, train_target)  # 計算損失\n",
    "        output_list.append(output)\n",
    "        # print(output.shape, train_target.shape)\n",
    "        loss.backward()  # 反向傳播\n",
    "        optimizer.step()  # 更新參數\n",
    "\n",
    "    losses.append(loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{n_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 打印最後的損失\n",
    "print(f'Final Loss: {loss.item():.4f}')\n",
    "print(len(losses))\n",
    "torch.cuda.empty_cache()\n",
    "##(unnormalize)\n",
    "##dropout=0.2  -> loss:6\n",
    "##dropout=0.1  -> loss:5.7\n",
    "##dropout=0.1  -> loss:5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f90c8-eedc-4ce2-90ce-80d299272dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印最後的損失\n",
    "print(len(losses))\n",
    "x_axis = np.arange(1, n_epochs+1)\n",
    "losses_tensor  = torch.stack(losses)\n",
    "loss_np = losses_tensor.cpu().detach().numpy()\n",
    "plt.plot(x_axis, loss_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20d77a-3461-4d13-8dc0-97367b2702e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 5\n",
    "x_test = data_tensor[:stamp, :7]\n",
    "y_test = data_tensor[:stamp, 7]\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(x_test.shape, y_test.shape)\n",
    "if NX:\n",
    "    test_data_n = scaler_X.transform(x_test)\n",
    "else:\n",
    "    test_data_n = x_test\n",
    "\n",
    "test_data_n = np.expand_dims(x_test, axis=0)\n",
    "\n",
    "test_data_n = torch.from_numpy(test_data_n).float().to(device)\n",
    "print(test_data_n.shape)\n",
    "\n",
    "out = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(test_data_n)\n",
    "    out_np  = out.cpu().numpy().squeeze().reshape(-1, 1)\n",
    "    # y_test = y_test.squeeze().reshape(-1, 1)\n",
    "    print(out_np.shape, y_test.shape)\n",
    "if NY:\n",
    "    # out_np = scaler_Y.inverse_transform(out_np)\n",
    "    # y_test = scaler_Y.inverse_transform(y_test)\n",
    "    out_np.squeeze()\n",
    "    \n",
    "    result = abs(y_test-out_np)\n",
    "else:\n",
    "    out_np.squeeze()\n",
    "    result = abs(y_test-out_np)\n",
    "print(out_np.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d241d-5257-468d-99c7-01fc42d384ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_re = result.reshape(result.shape[0]*result.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320d108-d83c-4cbe-b577-36802b63f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e574ab-8006-47e4-a978-d9fdc688027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_a = y_test.squeeze()\n",
    "show_b = out_np.squeeze()\n",
    "plt.plot(result_re, c = \"r\")\n",
    "plt.plot(show_a, c = \"b\")\n",
    "plt.plot(show_b, c = \"g\")\n",
    "plt.show()\n",
    "print(sum(result_re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f83451-a641-4f2b-9c5f-9af0eac75731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM 2 layers\n",
    "##(unnormalize)\n",
    "##dropout=0.2  -> loss:6\n",
    "##dropout=0.1  -> loss:5.7\n",
    "##dropout=0  -> loss:5.4\n",
    "# abs(583.7734)\n",
    "##(normalize x,y)  epoch 100\n",
    "##dropout=0.2 -> Loss: 0.0228\n",
    "##dropout=0.1 -> Loss: 0.0236\n",
    "##dropout=0 -> Loss: 0.0226\n",
    "# abs(5826.7388)\n",
    "##(normalize x only) epoch 300\n",
    "##dropout=0.2 -> Loss: 6.6351\n",
    "##dropout=0.1 -> Loss: 6.2561\n",
    "##dropout=0 -> Loss: 6.1234\n",
    "# abs(867)\n",
    "\n",
    "\n",
    "##transformer d_m=256, nhead=4, encoderlayer=3, dim_feed=1024, dropout= 0.1\n",
    "##(unnormalize) epoch 200\n",
    "#dropout= 0.1 -> Loss: 19.1384\n",
    "# abs(794.7)\n",
    "##(normalize x only)  epoch 200\n",
    "#dropout= 0.1 -> Loss: 21.35\n",
    "# abs(858)\n",
    "##transformer d_m=512, nhead=8, encoderlayer=6, dim_feed=2048, dropout= 0.1\n",
    "##(unnormalize) epoch 60\n",
    "#dropout= 0.1 -> Loss: 6.9705\n",
    "# abs(483.7)\n",
    "\n",
    "\n",
    "# lstm hidden_size1 = 128, hidden_size2 = 64 ,out_size = 1, num_layers = 1, \n",
    "# dropout = 0.2, learning_rate = 0.001, n_epochs = 100\n",
    "# NY=False on testing sum lastDAy, 450\n",
    "\n",
    "15028.978\n",
    "\n",
    "# transformer NY+NX=True, input_dim=7, d_model = 256, nhead = 4, num_encoder_layers = 3, dim_feedforward = 1024 , \n",
    "# dropout = 0.1, learning_rate = 0.00001, n_epochs = 150\n",
    "#sum lastDAy, 1865.8014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8e10a-31ea-48f9-bacc-d8598cc46a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94db973-703c-44c0-b402-ee4696b73969",
   "metadata": {},
   "outputs": [],
   "source": [
    "####transformer part:\n",
    "\n",
    "\n",
    "input_dim = 7  # 單變量的時間序列\n",
    "d_model = 256  #  Transformer embedding的維度\n",
    "nhead = 4     # 多頭注意力的頭數\n",
    "num_encoder_layers = 3  # Encoder的層數\n",
    "dim_feedforward = 1024  #Feedforward隱藏層的維度\n",
    "dropout = 0.1\n",
    "learning_rate = 0.00001\n",
    "n_epochs = 150\n",
    "\n",
    "# 模型初始化\n",
    "model = TimeSeriesTransformer(input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout).to(device)\n",
    "for train_input, train_target in train_loader:\n",
    "    print(train_input.shape, train_target.shape)\n",
    "    break\n",
    "criterion = nn.MSELoss()  # 使用均方誤差作為損失函數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "trans_loss = []\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # 設定模型為訓練模式\n",
    "    for train_input, train_target in train_loader:  # 從 DataLoader 獲取每個批次\n",
    "        train_input, train_target = train_input.to(device), train_target.to(device)\n",
    "        optimizer.zero_grad()  # 清空之前的梯度\n",
    "\n",
    "        output = model(train_input,train_target)  # 將掩碼傳遞給模型的前向方法train_target,\n",
    "        loss = criterion(output, train_target)  # 計算損失\n",
    "        # print(output.shape, train_target.shape)\n",
    "        loss.backward()  # 反向傳播\n",
    "        optimizer.step()  # 更新參數\n",
    "    trans_loss.append(loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{n_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 打印最後的損失\n",
    "print(f'Final Loss: {loss.item():.4f}')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce54a0b-3d02-4d34-8db6-a230ccf5a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trans_loss))\n",
    "x_axis = np.arange(1, n_epochs+1)\n",
    "losses_tensor  = torch.stack(trans_loss)\n",
    "loss_np = losses_tensor.cpu().detach().numpy()\n",
    "plt.plot(loss_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04641df1-d3e7-4890-a387-868b3b54daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc616b95-504b-44ba-9927-f97031caab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 5\n",
    "x_test = data_tensor[:stamp, :7]\n",
    "y_test = data_tensor[:stamp, 7]\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(x_test.shape, y_test.shape)\n",
    "if NX:\n",
    "    x_test = scaler_X.transform(x_test)\n",
    "else:\n",
    "    x_test = x_test\n",
    "if NY:\n",
    "    y_test = scaler_Y.transform(y_test)\n",
    "else:\n",
    "    y_test = Y_data_tensor\n",
    "x_test = np.expand_dims(x_test, axis=0)\n",
    "y_test = np.expand_dims(y_test, axis=0)  #or axis = 1?\n",
    "\n",
    "x_test = torch.from_numpy(x_test).float().to(device)\n",
    "y_test = torch.from_numpy(y_test).float().to(device)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "out = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x_test, y_test)\n",
    "    out_np  = out.cpu().numpy().squeeze().reshape(1, -1)\n",
    "    y_test = y_test.cpu().numpy().squeeze().reshape(1, -1)\n",
    "print(out_np.shape, y_test.shape)\n",
    "if NY:\n",
    "    ren_out_np = scaler_Y.inverse_transform(out_np)\n",
    "    y_test = scaler_Y.inverse_transform(y_test)\n",
    "    ren_out_np.squeeze()\n",
    "    result = abs(y_test-ren_out_np)\n",
    "else:\n",
    "    ren_out_np = out_np\n",
    "    result = abs(y_test-out_np)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d2855-af89-42d3-9eb1-eaea1e3beebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_tensor.shape)\n",
    "print(x_test.shape)\n",
    "print(train_targets_tensor.shape)\n",
    "print(y_test.shape)\n",
    "print(ren_out_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb4945-daa4-485c-b236-f52ecd5c8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_re = result.reshape(result.shape[0]*result.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac38ea-509d-4bdd-8b46-0058bf796b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_a = y_test.reshape(1,-1).squeeze()\n",
    "show_b = ren_out_np.reshape(1,-1).squeeze()\n",
    "# plt.plot(result_re, c = \"r\")\n",
    "plt.plot(show_a, c = \"b\")\n",
    "plt.plot(show_b, c = \"g\")\n",
    "plt.show()\n",
    "print(sum(result_re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e5135-66c9-4376-9abe-776003297bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 創建一個長度為 max_len 的位置編碼矩陣\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # 偶數位置\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # 奇數位置\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)  # 調整維度\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.input_layer = nn.Linear(input_dim, d_model)  # 將輸入轉換為 d_model 維度\n",
    "        self.target_input_layer = nn.Linear(1, d_model)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "                                          dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(d_model, 1)  # 回歸輸出\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        \n",
    "        src = self.input_layer(src)  # 映射到 d_model 維度\n",
    "        src = self.positional_encoding(src)  # 添加位置編碼\n",
    "\n",
    "        tgt = self.target_input_layer(tgt)  # 或者使用一個不同的線性層，例如 self.tgt_layer = nn.Linear(target_input_dim, d_model)\n",
    "        tgt = self.positional_encoding(tgt)  # 添加位置編碼\n",
    "    \n",
    "        output = self.transformer(src, tgt)   #(src, tgt, src_key_padding_mask=mask)\n",
    "        output = self.fc_out(output)  # 預測最後一個時間步的值\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600b63e-33b6-496b-8d02-474f273445c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
